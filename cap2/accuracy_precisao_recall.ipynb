{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificação: Thresholding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A regressão logistica retorna uma probabilidade. Voçe pode usar a probabilidade retornada \"como está\" (por exemplo, a probabilidade de o usuário clicar nesse anúncio pode ser 0.00023) ou conveter a probabilidade retornada em um valor binário (por exemplo, esse email é spam).\n",
    "\n",
    "Um modelo de regressão logística que retorna 0.9995 para uma mensagem de e-mail específica está prevendo que é muito provável que seja spam. Por outro lado, outra mensage de e-mail com uma pontuação de previsão de 0.0003 no mesmo modelo de regressão logística provavelmente não é spam. No entanto, que tal uma mensagem de email com uma pontuação de previsão de 0.6? Para mapear um valor de regressão logística para uma categoria binária, voce deve definir um limite de classificação (também chamado de limite de decisão). Um valor acima desse limite indica \"spam\"; um valor abaixo indica \"não é spam\". É tentador supor que o limiar de classificação deve sempre ser 0.5 mas os limites são dependentes do problema e, portanto, são valores que voce deve ajustar.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificação: Verdadeiro vs Falso e Positivo vs Negativo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Veradeiro Positivo (TP):\n",
    "    um verdadeiro positivo é um resultado em que o modelo prevê corretamente a classe positiva.\n",
    "- Verdadeiro Negativo (TN):\n",
    "    um resultado em que o modelo prevê corretamente a classe negativa.\n",
    "- Falso Positivo (FP):\n",
    "    um resultado em que o modelo prevê incorretamente a classe positiva.\n",
    "- Falso Negativo (FN):\n",
    "    um resultado em que o modelo prediz incorretamente a classe negativa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificação: Precisão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precisão é uma métrica para avaliar modelos de classificação. Informalmente, a precisão é a fração de previsões que nosso modelo acertou. Formalmente, a precisão tem a seguinte definição: \n",
    "\n",
    "Accuracy = Number of correct predictions / Total number of predictions\n",
    "\n",
    "Para classificação binária, a precisão também pode ser calculada em termos de positivos e negativos,como segue: \n",
    "\n",
    "Accuracy = TP + TN / TP + TN + FP + FN\n",
    "\n",
    "Exemplo: Vamos tentar calcular a precisão para o modelo que classificou 100 tumores como malignos(classe positiva) ou benignos(classe negativa):\n",
    "\n",
    "TP = 1\n",
    "FP = 1\n",
    "FN = 8\n",
    "TN = 90\n",
    "\n",
    "Accuracy = 1+90/1+90+1+8 = 0.91\n",
    "\n",
    "A precisão chega a 0.91 ou 91% (91 previsões corretas de 100 exemplos no total). Isso significa que nosso classificador de tumores está fazendo um ótimo trabalho na identificação de malignidades, certo?\n",
    "\n",
    "Na verdade, vamos fazer uma análise mais detalhada de aspectos positivos e negativos para obter informações sobre o desempenho do nosso modelo.\n",
    "\n",
    "Dos 100 exemplos de tumores, 91 são benignos (90 TNs e 1 FP) e 9 são malignos (1 TP e 8 FNs)\n",
    "\n",
    "Dos 91 tumores, o modelo identifica corretamente 90 benigno. Isso é bom. No entanto, dos 9 tumores malignos, o modelo identifica apenas 1 maligno - um resultado terrivel, pois 8 de 9 malignidades não são diagnsticadas!\n",
    "\n",
    "A precisão por si só , naõ conta a história completa quando voçe está trabalhando com um conjunto de dados desbalanceado de classe, como este, em que há uma disparidade significativa entre o número de rótulos positivos e negativos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificação: Precisão e Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A precisão tenta responder à seguinte pergunta:\n",
    "    Que proporção de identificação positivas foi realmente correta?\n",
    "    A precisão é definida da seguinte forma:\n",
    "    Precision = TP/TP + FP\n",
    "    \n",
    "Precision = TP / TP + FP = 1/1+1 = 0.5\n",
    "\n",
    "nosso modelo tem uma precisão de 0.5 - em outras palavras, quando prevÊ que um tumor é maligno, está correto em 50% das vezes.\n",
    "\n",
    "Lembre-se de tentar responder a seguinte pergunta:\n",
    "\n",
    "Qual proporção de positivos reais foi identificada corretamente?\n",
    "\n",
    "Matematicamente, a recordação é definida da seguinte forma: \n",
    "\n",
    "Recall = TP/TP + FN\n",
    "\n",
    "Recall = 1/1+8 = 0.11\n",
    "\n",
    "Nosso modelo tem uma recordação de 0.11 - em outras palavras, identifica corretamente 11% de todos os tumores malignos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F-score para um limiar para classificação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 = 2 . precision . recall/ precision + recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-score:  0.33\n"
     ]
    }
   ],
   "source": [
    "f1 = 2*0.5*0.11/0.5+0.11\n",
    "print(\"F-score: \",f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
